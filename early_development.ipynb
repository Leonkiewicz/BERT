{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore MovieDialogs Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example text in movie_lines.txt:\n",
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n",
      "Example text in movie_converstations.txt:\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "\n",
      " ['L194', 'L195', 'L196', 'L197']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_movie_conv = 'datasets/cornell movie-dialogs corpus/movie_conversations.txt'\n",
    "corpus_movie_lines = 'datasets/cornell movie-dialogs corpus/movie_lines.txt'\n",
    "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
    "    conv = c.readlines()\n",
    "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
    "    lines = l.readlines()\n",
    "print(f\"Example text in movie_lines.txt:\\n{lines[0]}{lines[1]}\")\n",
    "print(f\"Example text in movie_converstations.txt:\\n{conv[0]}{conv[1]}\")\n",
    "\n",
    "\n",
    "# movie_lines structure\n",
    "# line_id +++$+++ character_id +++$+++ movie_id +++$+++ character_name(?) +++$+++ conversation line\n",
    "\n",
    "# movie_conversations structure\n",
    "# character_id +++$+++ reply_to_id (spoken to) +++$+++ movie_id +++$+++ line_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping L474 as it's missing text: ['L474', 'u5', 'm0', 'KAT +++$+++']\n",
      "Skipping L24609 as it's missing text: ['L24609', 'u224', 'm14', 'SYKES +++$+++']\n",
      "Skipping L239088 as it's missing text: ['L239088', 'u1125', 'm74', 'JANOSZ +++$+++']\n",
      "Skipping L283548 as it's missing text: ['L283548', 'u1356', 'm90', 'BRUCE +++$+++']\n"
     ]
    }
   ],
   "source": [
    "pairs, lines_dict = prepare_qa_pairs(lines, conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WordPiece tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT uses WordPiece embeddings with 30k token vocabulary\n",
    "# The first token of every sequence is always a special classification token ([CLS])\n",
    "# Sentence pairs are packed together into a single sequence.\n",
    "# They are separated with special token ([SEP]), also a learned embedding is added to every token, which indicates if it belongs to sentence A or Sentence B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221282/221282 [00:00<00:00, 4175002.71it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_text_batches(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\R2G\\OpenAI\\llm_venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1945: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "chunk_paths = [os.path.join('./datasets/MovieDialogsChunks/', x) for x in os.listdir('./datasets/MovieDialogsChunks')]\n",
    "train_tokenizer(chunk_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
